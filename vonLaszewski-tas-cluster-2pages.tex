\documentclass[10pt, conference, compsocconf]{IEEEtran}

\hyphenation{data-bases}

\newcommand{\TITLE}{Peer comparison of XSEDE and NCAR publication data}
\newcommand{\AUTHOR}{Gregor von Laszewski, Fugang Wang}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LATEX DEFINITIONS 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{cite}
\usepackage{float}
\usepackage{comment}
\usepackage{hyperref} 
\usepackage{array} 
\usepackage{graphicx} 
\usepackage{booktabs} 
\usepackage{pifont} 
\usepackage{todonotes} 
\usepackage{rotating} 
\usepackage{color} 
\usepackage{caption}
\captionsetup{font={scriptsize}}

\newcommand*\rot{\rotatebox{90}} 
 
\newcommand{\FILE}[1]{\todo[color=green!40]{#1}} 
 

%
% more floats on one page
%
\renewcommand{\topfraction}{.85}
\renewcommand{\bottomfraction}{.7}
\renewcommand{\textfraction}{.15}
\renewcommand{\floatpagefraction}{.66}
\renewcommand{\dbltopfraction}{.66}
\renewcommand{\dblfloatpagefraction}{.66}
\setcounter{topnumber}{9}
\setcounter{bottomnumber}{9}
\setcounter{totalnumber}{20}
\setcounter{dbltopnumber}{9}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% HYPERSETUP 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hypersetup{ 
    bookmarks=true,         % show bookmarks bar 
    unicode=false,          % non-Latin characters in Acrobat's bookmarks 
    pdftoolbar=true,        % show Acrobat's toolbar 
    pdfmenubar=true,        % show Acrobat's menu 
    pdffitwindow=false,     % window fit to page when opened 
    pdfstartview={FitH},    % fits the width of the page to the window 
    pdftitle={\TITLE},    % title 
    pdfauthor={\AUTHOR},     % author 
    pdfsubject={Subject},   % subject of the document 
    pdfcreator={Gregor von Laszewski, Fugang Wang},   % creator of the document 
    pdfproducer={}, % producer of the document 
    pdfkeywords={hindex} {metric}{XSEDE} {FutureGrid}, % list of keywords 
    pdfnewwindow=true,      % links in new window 
    colorlinks=false,       % false: boxed links; true: colored links 
    linkcolor=red,          % color of internal links (change box color with linkbordercolor) 
    citecolor=green,        % color of links to bibliography 
    filecolor=magenta,      % color of file links 
    urlcolor=cyan           % color of external links 
} 

\begin{document}

\begin{comment}
%\conferenceinfo{submitted to XSEDE}{'15,  July 26 - 30 2015, St. Louis, MO, USA}
\conferenceinfo{submitted to ...}{2015,USA}
\CopyrightYear{2015} 
\crdata{TBD...\$15.00.\\
http://dx.doi.org/TBD
} 
\end{comment}

\title{\TITLE\vspace{-12pt}}



\begin{comment}
\numberofauthors{3}  
\author{ 
\alignauthor 
Gregor von Laszewski\titlenote{Corresponding Author.}\\ \vspace{2pt}
Fugang Wang\\ \vspace{2pt}
Geoffrey C. Fox\\ \vspace{6pt}
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
\and  
\alignauthor  David L. Hart\\ \vspace{6pt}
       \affaddr{Computational and Information Systems Laboratory National Center for Atmospheric Research}\\
       \affaddr{P.O. Box 3000}\\
       \affaddr{Boulder CO 80307-3000}\\
\and
\alignauthor  
Thomas R. Furlani\\ \vspace{2pt}
Robert L. DeLeon\\ \vspace{2pt}
Steven M. Gallo\\ \vspace{6pt}
       \affaddr{Center for Computational Research}\\
       \affaddr{University at Buffalo, SUNY}\\ 
       \affaddr{701 Ellicott Street}\\ 
       \affaddr{Buffalo, New York, 14203}
}

\date{28 May 2014}
\end{comment}

\begin{comment}
\author{\IEEEauthorblockN{%
Gregor von Laszewski,
Fugang Wang,
Geoffrey C. Fox}
\IEEEauthorblockA{School of Informatics and Computing\\
Indiana University\\
Bloomington, Indiana, U.S.A.\\
laszewski@gmail.com}
\and
\IEEEauthorblockN{David L. Hart}
\IEEEauthorblockA{%
Computational and Information Systems Laboratory\\
NCAR\\
Boulder CO 80307-3000}
\and
\IEEEauthorblockN{Thomas R. Furlani,
Robert L. DeLeon,
Steven M. Gallo}
\IEEEauthorblockA{%
Center for Computational Research\\
University at Buffalo, SUNY\\ 
Buffalo, New York, 14203}
}
\end{comment}

\author{\IEEEauthorblockN{%
Gregor von Laszewski$^1$,
Fugang Wang$^1$,
Geoffrey C. Fox$^1$
David L. Hart$^2$\\
Thomas R. Furlani$^3$,
Robert L. DeLeon$^3$,
Steven M. Gallo$^3$}
\IEEEauthorblockA{%
$^1$School of Informatics and Computing, Indiana University, Bloomington, Indiana, U.S.A.\\
$^2$Computational and Information Systems Laboratory, NCAR, Boulder CO 80307-3000, U.S.A.\\
$^3$Center for Computational Research, University at Buffalo, SUNY, Buffalo, New York, 14203, U.S.A.\\
 laszewski@gmail.com}
}

\maketitle

\begin{abstract}

We present a framework that compares the publication impact based on a comprehensive peer analysis of papers produced by scientists using XSEDE and NCAR resources. The analysis is introducing a percentile ranking of citations of the XSEDE and NCAR papers compared to peer publications in the same journal that do not use these resources.  This analysis is unique in that it is a comprehensive study in which all reported published papers are compered to peer publications selected from within the same issue of the same journal. From this analysis, we can see that papers that utilize XSEDE and NCAR resources are cited statistically significantly more often.  Hence we find that reported publications indicate that XSEDE and NCAR resources exert a strong positive impact on scientific research.

\end{abstract}

\begin{comment}
\vspace{-6pt}

\category{H.4}{Information Systems Applications}{Miscellaneous}
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures,
performance measures]

\terms{Theory, Measurement}

\keywords{Scientific impact, bibliometric, h-index, Technology Audit
  Service, XDMoD, XSEDE}
\end{comment}

\section{Introduction} 


We analyze the scientific impact on {\em scientific advancements enabled by enhanced cyberinfrastructure} for XSEDE and NCAR resources. We extend our previous work \cite{las14impact} by comparing publication impact based on a comprehensive peer analysis carried out on papers produced by scientists using XSEDE and National Center for Atmospheric Research (NCAR) resources \cite{las15cluster-long,las15xsede}. The analysis is based on a percentile ranking of citations of the papers derived from a comparison to peer publications in the same journal not using the resources. The result shows that papers that utilize XSEDE and NCAR resources tend to be cited more often than their peers are cited. We leverage for our work our data collection architecture described in \cite{las14impact,las15cluster-long} which will be accessible through XDMoD \cite{Furlani:2013:UXF:2484762.2484763}. 

To conduct the analysis, the general workflow includes obtaining the publication data for each XSEDE user, and then retrieving the citation data for each publication. Hence, the data is originally collected on a per-user and per-publication basis. As part of processing, the data are aggregated based on organization, XSEDE project/account, and FOS.  By correlating the publication data with XSEDE usage and allocation data (for example the allocation amounts awarded by XSEDE), our intention is to determine if the analysis reveals patterns and trends in how XSEDE impacts the sciences and possibly to help better measure the return on investment (ROI) for NSF. Naturally, the same is applied to the NCAR data to demonstrate the generality of our methods.

\section{Metric for Journal Publication-based Peer Comparison} \label{S:metric}

We compared studied (from XSEDE and NCAR) publications with their peers by looking at the citation count and relative ranking. The process is as the following:
\begin{enumerate}
\item Identify publication venues of the reported XSEDE or NCAR publications;
\item Retrieve all publication data from those venues during the same time period;
\item Identify the peers comparison groups (All publications in same journal issues);
\item Calculate ranking scores of XSEDE publications and their peers;
\item Use the raw ranking scores to derive comparison metrics at different aggregation level (e.g. journal, Field of Study).
\end{enumerate}

During this process we have retrieved more than one million publication records to facilitate the peers comparison.

We also identified a performance score based on weighted sums of the percentages of publications falling into each quarter by percentile ranking.:

\[	S = 1*P_{Q_1} + 0.5*P_{Q_2}+ (-0.5)*P_{Q_3} + (-1)*P_{Q_4} \]

In which, $P_{Q_i}$ is the percentage of publications falling into the top i quarter. $P_{Q_i}$ gets the value in $[0,1]$ and $\sum_{i} {P_{Q_i}} = 1$ for one FOS.

It is trivial to see that $S$ has its value from $[-1, 1]$. A positive value implies more publications appear in the upper half in ranking and negative means more in the lower half.

\section{XSEDE Peer Data Analysis}
\label{S:xsede}

To apply the percentile ranking to the field of science of XSEDE/TG publications among the journal issues where each publication was published, we aggregate them based on FOS, and calculate the average and median percentile ranking for each field of science, as well as the resulting  \emph{performance score}. We include only those with at least ten\footnote{For NCAR data, we used a value of five due to the smaller number of overall publications} publications so the results have a higher statistical power. 

Table \ref{T:groups_stats} lists the average and median rankings and citations received of the two groups to evaluate and compare. The results from t-test show that the XSEDE group has a statistically higher citation ranking and a statistically higher  mean citation rate than the non-XSEDE peer group.

\begin{table}[h!]
\caption{Basic statistics of XSEDE publications group and peers group}
\label{T:groups_stats}
\centering
\begin{small}
\begin{tabular}{lrrrrrr}
 & Number of & \multicolumn{2}{ c }{Rank} & \multicolumn{2}{ c }{Citations}  \\
 &  Publications & Average & Median & Average & Median \\
\hline
  XD     & 2349	        & 61	& 65	& 26	& 11 \\
Peers & 168422	& 49	& 48	& 13	& 5 \\
\end{tabular}
\end{small}
\end{table}

\begin{enumerate}
\item T-test for ranking (Welch Two sample t-test)
\begin{enumerate}
\item T=21.4134, df=2412.99, p-value<2.2e-16
\item 95\% confidence interval: $[10.80, 12.98]$
\end{enumerate}
\item T-test for citation count:
\begin{enumerate}
\item T=7.057, df=2358.929, p-value=2.228e-12
\item 95\% confidence interval: $[9.40, 16.63]$
\end{enumerate}
\end{enumerate}



\begin{figure}[H]
\includegraphics[width=.9\columnwidth]{images-new/xsede-journal-score.pdf} 
\vspace{-6pt}
\caption{The score of our peer comparison metric for XSEDE publications by journal.}\label{F:xsede-score}

  \centering 
    \includegraphics[width=1.0\columnwidth]{images-new/b.pdf} 
\vspace{-18pt}
  \caption{Peer comparison based on Parent Field of Science from the original analysis of XSEDE data.}\label{F:xsede-stacked-b} 

  \centering 
    \includegraphics[width=1.0\columnwidth]{images-new/ncar-c.pdf} 
\vspace{-18pt}
  \caption{Peer comparison based on Parent Field of Science from the original analysis of NCAR data.}\label{F:ncar-score}
\end{figure} 







\begin{comment}

    \includegraphics[width=1.0\columnwidth]{images-new/c.pdf} 
  \caption{Peers comparison based on the topmost Field of Science category as defined by NSF.}\label{F:xsede-top-c} 

\hfill



\begin{figure*}[htb!] 
  \centering 
    \includegraphics[width=1.0\textwidth]{images-new/xsede-journal-stacked.pdf} 
  \caption{Percentile ranking by journal in a stacked barchart of XSEDE publications.}\label{F:xsede-stacked} 
\end{figure*}

\bigskip

\end{comment}


The results are depicted in Figures \ref{F:xsede-stacked}, \ref{F:xsede-stacked-b}, \ref{F:xsede-score}, and \ref{F:xsede-top-c}. 

NSF and XSEDE define a hierarchy of FOSs. In Figure \ref{F:xsede-top-c}, we show the top level FOS as defined by NSF. When we look to expand the FOS to the next level in the hierarchy, we find the results as depicted in Figure \ref{F:xsede-stacked-b}. The next level is shown in Figure \ref{F:xsede-fos-a}. Each of these figures shows the list of FOSs in decreasing order by the performance score $S$. 

From Figure \ref{F:xsede-fos-b} we can identify that for most fields of science the XSEDE publications performed better than their peers. The average and median scores were higher than 50 and the score is positive. When looking at individual results, we see that astronomy and physics benefit most from using XSEDE/TG. When looking at the fields that perform worst, we find fields such as Experimental and Theoretical Geochemistry, Geometric Analysis and Mechanical and Structural systems. Such fields are typically not dominated by simulation science and are less dependent on computational resources. Other fields such as Training include many other areas of training outside of supercomputing usage. We even find fields such as Computer and Computation Research to be less impacted. We certainly have to acknowledge in this case that many theoretical papers and papers not using supercomputers are published. 

To show the percentile distribution in more detail for each journal, we present in Figure \ref{F:xsede-stacked} a stacked barchart. Also here, as expected from our previous results, we see a positive impact in the percentile citation count for most of the journals. This is made obvious by looking at Figure \ref{F:xsede-score}. Here we also have included the average of the top 66 journals in which we found 10 or more XSEDE publications and find that the score metric is positive with a value of 0.284. Thus we can conclude that papers benefit from use of XSEDE resources, based on self-identification in reports and bibliographic upload to the XSEDE portal, resulting in their being more cited on average than their peers from the same journal.

\section{NCAR Peer Data Analysis}\label{S:ncar}

\begin{comment}
  \centering 
    \includegraphics[width=0.75\columnwidth]{images-new/ncar-a.pdf} 
  \caption{Distribution of the top most journals by publication count.}\label{F:ncar-distribution} 

  \centering 
    \includegraphics[width=1.0\columnwidth]{images-new/ncar-b.pdf} 
  \caption{Percentile ranging by FOS in a stacked barchart of NCAR publications.}\label{F:ncar-stacked-b} 
\end{comment}



We have replicated the publication citation analysis with a text file of 880 publications obtained from NCAR. Because the NCAR data set was smaller than the one from XSEDE, instead of looking at all journals that have at least ten publications, we reduced the value to five. This will give a large enough journal number to conduct our analysis in this case. To conduct the analysis, we took the following steps.

\begin{enumerate}

\item We parsed the text file containing 880 publications into a structured database while identifying titles, and DOIs.

\item With our framework, we queried ISI Web of Knowledge to get detailed information on the publications -- journal name, issue, citation data and other identifying information. We were able to verify and obtain data for 813 publications.

\item Through our framework, we identified and obtained peer data based on journal issue information. In total, 130 different publication venues have been identified. To ensure the results are statistically meaningful, we eliminated those with less than five publications appearing in them.  This leads to 35 different journals that cover 653 publications. Out of the 35 journals, we had peers data for 12 of them (from our XSEDE peers comparison work). For the other 23 journals, we obtained peer publication data for an additional 39,000 publications.

\item For each NCAR publication, we computed the percentile ranking among peers within the same journal issue against all publication entries as obtained from ISI Web of Knowledge.

\item We grouped the percentile ranking scores based on each journal, divided the scores into each ranking quarters ($Q_1$: top 25\%; top $Q_2$: 25\%~50\%; bottom $Q_3$: 50\%-75\%, bottom $Q_4$: 75\%-100\%), and computed the percentage for those that fall into each ranking quarter.

\end{enumerate}

We depict the result in a stacked column chart similar to that used in Figure \ref{F:xsede-stacked}.  In Figure \ref{F:ncar-distribution}, we show the distribution of the publications in the top 10 journals sorted by the number of publications. The top 10 journals total 484 publications. They account for about three quarters of the 653 publications from the 35 journals with at least five publications appearing in them; or 60\% of the 813 publications from the 130 journals we identified via the ISI source (see Table~\ref{T:ncar-pub-count-venue}).

We also computed and compared the \emph{performance score} as defined earlier. The result is shown in Figure \ref{F:ncar-score}. Here we see that the average over all 35 entries is a positive value of about 0.35. 

\section{Conclusion} \label{S:conclusion}

NCAR score is slightly higher than that of XSEDE as XSEDE has a wider range of FOS. Computational intense disciplines such as atmospheric sciences result in the highest score values using the resources. For both XSEDE and NCAR publications, the impact measured by a percentile score is positive and higher than their peers that have not used such resources.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Acknowledgment 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section*{Acknowledgments}

Supported by NSF \#1445806 influenced by 0910812.
 

%\bibliographystyle{IEEEtranS}
%\bibliographystyle{abbrvurl} 
\bibliographystyle{IEEEtran}
\bibliography{% 
bib/tas,%
bib/vonlaszewski-jabref,%
bib/vonlaszewski-new} 



\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%